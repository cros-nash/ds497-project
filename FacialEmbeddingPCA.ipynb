{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674ea16a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f2758",
   "metadata": {},
   "source": [
    "## Loading the images to create facial embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66db386c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.image_width = 128\n",
    "        self.image_height = 128\n",
    "        self.epoch = 5\n",
    "        self.seed = 42\n",
    "        self.batch_size = 64\n",
    "        self.dataset_path = './DATASET'\n",
    "        # self.checkpoint_filepath = 'model_checkpoint.h5'\n",
    "        # self.logs_path = '/kaggle/working/logs'\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbab62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# If device is \"cuda\" then GPU is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print (f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa1381",
   "metadata": {},
   "source": [
    "Converting the dataset into a dataframe and also converting png files into jpg files for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5bf36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\"image_path\":[],\"img_status\":[],\"where\":[]}\n",
    "pattern = re.compile(r'^(.*)\\.png$')\n",
    "\n",
    "for where in ['fake', 'real']:\n",
    "    for status in os.listdir(config.dataset_path+\"/\"+where):\n",
    "        for image in glob.glob(os.path.join(config.dataset_path, where, status)):\n",
    "\n",
    "            match_obj = pattern.match(image)\n",
    "            if match_obj:\n",
    "                name_without_ext = match_obj.group(1)\n",
    "                convert = Image.open(image).convert('RGB')\n",
    "                jpg_path = name_without_ext + \".jpg\"\n",
    "                convert.save(jpg_path)\n",
    "                image = jpg_path\n",
    "                \n",
    "            dataset[\"image_path\"].append(image)\n",
    "            dataset[\"img_status\"].append(status)\n",
    "            dataset[\"where\"].append(where)\n",
    "\n",
    "dataset = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e46777c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>img_status</th>\n",
       "      <th>where</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./DATASET/fake/person(100).jpg</td>\n",
       "      <td>person(100).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./DATASET/fake/person(98).jpg</td>\n",
       "      <td>person(98).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./DATASET/fake/person(87).jpg</td>\n",
       "      <td>person(87).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./DATASET/fake/person(62).jpg</td>\n",
       "      <td>person(62).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./DATASET/fake/person(92).jpg</td>\n",
       "      <td>person(92).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./DATASET/fake/person(63).jpg</td>\n",
       "      <td>person(63).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./DATASET/fake/person(69).jpg</td>\n",
       "      <td>person(69).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./DATASET/fake/person(81).jpg</td>\n",
       "      <td>person(81).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./DATASET/fake/person(51).jpg</td>\n",
       "      <td>person(51).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./DATASET/fake/person(56).jpg</td>\n",
       "      <td>person(56).jpg</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       image_path       img_status where\n",
       "0  ./DATASET/fake/person(100).jpg  person(100).jpg  fake\n",
       "1   ./DATASET/fake/person(98).jpg   person(98).jpg  fake\n",
       "2   ./DATASET/fake/person(87).jpg   person(87).jpg  fake\n",
       "3   ./DATASET/fake/person(62).jpg   person(62).jpg  fake\n",
       "4   ./DATASET/fake/person(92).jpg   person(92).jpg  fake\n",
       "5   ./DATASET/fake/person(63).jpg   person(63).jpg  fake\n",
       "6   ./DATASET/fake/person(69).jpg   person(69).jpg  fake\n",
       "7   ./DATASET/fake/person(81).jpg   person(81).jpg  fake\n",
       "8   ./DATASET/fake/person(51).jpg   person(51).jpg  fake\n",
       "9   ./DATASET/fake/person(56).jpg   person(56).jpg  fake"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.reset_index(drop=True)\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9f91e3",
   "metadata": {},
   "source": [
    "Here is the model architecture of the pre-trained model we are going to use to generate the facial embeddings. \n",
    "\n",
    "We'll create a function that returns the activations from the pen-ultimate layer so that we can get the facial embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009ce71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = models.__dict__[model_name](pretrained=True)\n",
    "        \n",
    "        if 'vgg' in model_name:\n",
    "            num_features = self.model.classifier[6].in_features\n",
    "            self.model.classifier[6] = nn.Sequential(\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "            \n",
    "        elif 'mobilenet' in model_name:\n",
    "            num_features = self.model.classifier[1].in_features\n",
    "            self.model.classifier = nn.Sequential(\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "            \n",
    "        else:\n",
    "            num_features = self.model.fc.in_features\n",
    "            self.model.fc = nn.Sequential(\n",
    "                nn.Linear(num_features, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(512),\n",
    "                nn.Linear(512, num_classes)\n",
    "            )\n",
    "            \n",
    "        self.val_loss = []\n",
    "        self.val_accuracy = []\n",
    "        self.train_loss = []\n",
    "        self.train_accuracy = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def print_model_summary(self):\n",
    "        print(self.model)\n",
    "        print(\"Model Summary:\")\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        print(f\"Total Parameters: {total_params}\")\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        print(f\"Trainable Parameters: {trainable_params}\")\n",
    "\n",
    "    def plot_metrics_graph(self):\n",
    "        epochs = range(1, len(self.train_loss) + 1)\n",
    "\n",
    "        plt.figure(figsize=(12, 8))\n",
    "\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.plot(epochs, self.train_loss, label='Train Loss', linewidth=2, color='blue')\n",
    "        plt.plot(epochs, self.val_loss, label='Validation Loss', linewidth=2, color='orange')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training and Validation Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.plot(epochs, self.train_accuracy, label='Train Accuracy', linewidth=2, color='green')\n",
    "        plt.plot(epochs, self.val_accuracy, label='Validation Accuracy', linewidth=2, color='red')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_confusion_matrix(self, y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.show()\n",
    "\n",
    "    def train_model(self, train_loader, valid_loader, num_epochs, device):\n",
    "        criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss\n",
    "        optimizer = optim.Adam(self.parameters(), lr=0.001)\n",
    "\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.2, patience=3, verbose=True, min_lr=1e-6)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()  # Set the model to training mode\n",
    "            total_loss = 0.0\n",
    "            correct_train = 0\n",
    "            total_train = 0\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] - Training...\")\n",
    "\n",
    "            for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item() * inputs.size(0)\n",
    "                predicted_labels = (outputs >= 0.0).float()\n",
    "                correct_train += (predicted_labels == labels.float().unsqueeze(1)).sum().item()\n",
    "                total_train += labels.size(0)\n",
    "\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}] - Batch [{batch_idx+1}/{len(train_loader)}] - \"\n",
    "                      f\"Loss: {loss.item():.4f} - Train Accuracy: {correct_train / total_train:.4f}\")\n",
    "\n",
    "            average_loss = total_loss / len(train_loader.dataset)\n",
    "            train_accuracy = correct_train / total_train\n",
    "\n",
    "            self.train_loss.append(average_loss)\n",
    "            self.train_accuracy.append(train_accuracy)\n",
    "\n",
    "            self.eval()\n",
    "            total_val_loss = 0.0\n",
    "            correct_val = 0\n",
    "            total_val = 0\n",
    "\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in valid_loader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    outputs = self(inputs)\n",
    "                    val_loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "                    total_val_loss += val_loss.item() * inputs.size(0)\n",
    "                    predicted_labels = (outputs >= 0.0).float()\n",
    "                    correct_val += (predicted_labels == labels.float().unsqueeze(1)).sum().item()\n",
    "                    total_val += labels.size(0)\n",
    "\n",
    "                    y_true.extend(labels.float().unsqueeze(1).cpu().numpy())\n",
    "                    y_pred.extend(predicted_labels.cpu().numpy())\n",
    "\n",
    "            average_val_loss = total_val_loss / len(valid_loader.dataset)\n",
    "            val_accuracy = correct_val / total_val\n",
    "\n",
    "            self.val_loss.append(average_val_loss)\n",
    "            self.val_accuracy.append(val_accuracy)\n",
    "\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "                  f\"Train Loss: {average_loss:.4f} - Train Accuracy: {train_accuracy:.4f} - \"\n",
    "                  f\"Val Loss: {average_val_loss:.4f} - Val Accuracy: {val_accuracy:.4f} - \"\n",
    "                  f\"LR: {scheduler.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "            scheduler.step(average_val_loss)\n",
    "        \n",
    "        self.plot_metrics_graph()\n",
    "        self.plot_confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "    def get_embedding(self, x):\n",
    "        \"\"\"\n",
    "        Returns the 512-dim embedding (the output of the penultimate layer)\n",
    "        before the final classification linear layer.\n",
    "        \"\"\"\n",
    "\n",
    "        backbone_layers = list(self.model.children())[:-1]\n",
    "        backbone = nn.Sequential(*backbone_layers)\n",
    "        features = backbone(x)\n",
    "\n",
    "        features = features.view(features.size(0), -1)\n",
    "\n",
    "        partial_fc = self.model.fc[0:3]\n",
    "\n",
    "        embedding_512 = partial_fc(features)\n",
    "        return embedding_512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510cdcc1",
   "metadata": {},
   "source": [
    "Loading the pre-trained model and using same parameters it was generated with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4857f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/one6ix/Documents/GitHub/ds497/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/one6ix/Documents/GitHub/ds497/.venv/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (model): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the custom model\n",
    "num_classes = 1  # Change this to your number of classes\n",
    "model_name = \"resnet18\"  # Change this to any model available in torchvision\n",
    "#model_name = \"vgg16\" \n",
    "model = CustomModel(model_name=model_name, num_classes=num_classes)\n",
    "model.load_state_dict(torch.load('model-resnet18.pth', weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff2e225",
   "metadata": {},
   "source": [
    "Resize images, convert images to tensor and normalize according to ML architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d84e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f25d004",
   "metadata": {},
   "source": [
    "Create the embeddings, by applying transforms, ensuring all images are jpg files, then converting embedding matrix into a numpy array and adding it to the embed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09542fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = []\n",
    "\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for idx, row in dataset.iterrows():\n",
    "    img_path = row[\"image_path\"]\n",
    "    pil_image = Image.open(img_path).convert('RGB')\n",
    "    input_tensor = transform(pil_image).unsqueeze(0)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embedding(input_tensor)\n",
    "\n",
    "    embeddings = embeddings.squeeze(0).cpu().numpy()\n",
    "\n",
    "    embeddings_list.append(embeddings)\n",
    "\n",
    "embed_dataset = pd.DataFrame()\n",
    "embed_dataset[\"embeddings\"] = embeddings_list\n",
    "embed_dataset[\"label\"] = dataset['where'].values\n",
    "embed_dataset[\"image\"] = dataset['img_status'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6995a986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1.0704213e-06, 0.061032012, 0.0040942924, -0....</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(100).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1.0704213e-06, 0.2515665, 0.0040942924, -0.26...</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(98).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1.0704213e-06, 0.13312046, 0.0040942924, -0.1...</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(87).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1.0704213e-06, 0.4988383, 0.0040942924, -0.48...</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(62).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1.0704213e-06, 1.1278788, 0.0040942924, -1.15...</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(92).jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          embeddings label            image\n",
       "0  [1.0704213e-06, 0.061032012, 0.0040942924, -0....  fake  person(100).jpg\n",
       "1  [1.0704213e-06, 0.2515665, 0.0040942924, -0.26...  fake   person(98).jpg\n",
       "2  [1.0704213e-06, 0.13312046, 0.0040942924, -0.1...  fake   person(87).jpg\n",
       "3  [1.0704213e-06, 0.4988383, 0.0040942924, -0.48...  fake   person(62).jpg\n",
       "4  [1.0704213e-06, 1.1278788, 0.0040942924, -1.15...  fake   person(92).jpg"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dataset.to_pickle(\"embed_dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0698326",
   "metadata": {},
   "source": [
    "## USING PCA TO REDUCE DIMENSIONALITY OF DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d6b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake' 'real']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.605235</td>\n",
       "      <td>0.667623</td>\n",
       "      <td>0.451399</td>\n",
       "      <td>0.178196</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.066833</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>-0.005950</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(100).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.719081</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>0.265268</td>\n",
       "      <td>-0.193788</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>-0.011615</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>-0.012654</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(98).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.318301</td>\n",
       "      <td>0.773588</td>\n",
       "      <td>0.247358</td>\n",
       "      <td>0.162311</td>\n",
       "      <td>0.039235</td>\n",
       "      <td>0.048782</td>\n",
       "      <td>-0.041743</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(87).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.963363</td>\n",
       "      <td>-0.378007</td>\n",
       "      <td>0.150066</td>\n",
       "      <td>-0.258504</td>\n",
       "      <td>-0.005361</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(62).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.145729</td>\n",
       "      <td>0.939426</td>\n",
       "      <td>0.297938</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>-0.039451</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>-0.018045</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(92).jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0 -11.605235  0.667623  0.451399  0.178196  0.035186  0.002500 -0.066833   \n",
       "1  -8.719081  0.121731  0.265268 -0.193788  0.015589  0.039432 -0.011615   \n",
       "2 -10.318301  0.773588  0.247358  0.162311  0.039235  0.048782 -0.041743   \n",
       "3  -4.963363 -0.378007  0.150066 -0.258504 -0.005361  0.009539  0.043594   \n",
       "4   6.145729  0.939426  0.297938  0.055525  0.046462 -0.039451  0.013124   \n",
       "\n",
       "          7         8         9 label            image  \n",
       "0  0.008642  0.003546 -0.005950  fake  person(100).jpg  \n",
       "1 -0.007887  0.020599 -0.012654  fake   person(98).jpg  \n",
       "2  0.026801  0.020383 -0.009967  fake   person(87).jpg  \n",
       "3  0.005366 -0.017333  0.011270  fake   person(62).jpg  \n",
       "4 -0.018045  0.000462  0.000765  fake   person(92).jpg  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dataset = pd.read_pickle('embed_dataset.pkl')\n",
    "embedding_matrix = np.vstack(embed_dataset[\"embeddings\"].values)\n",
    "labels = embed_dataset[\"label\"].values\n",
    "image = embed_dataset[\"image\"].values\n",
    "\n",
    "print(np.unique(labels))\n",
    "\n",
    "dims_to_try = [1, 2, 3, 4, 5, 10, 20, 30, 50, 100]\n",
    "pca_dfs = {}\n",
    "\n",
    "for d in dims_to_try:\n",
    "    pca = PCA(n_components=d)\n",
    "    reduced_embeddings = pca.fit_transform(embedding_matrix)\n",
    "    pca_df = pd.DataFrame(reduced_embeddings)\n",
    "    pca_df[\"label\"] = labels\n",
    "    pca_df[\"image\"] = image\n",
    "    pca_dfs[d] = pca_df\n",
    "\n",
    "pca_dfs[10].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abcb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in pca_dfs.keys():\n",
    "    pca_dfs[x].to_pickle(\"df_pca_\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de28f14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-11.605235</td>\n",
       "      <td>0.667623</td>\n",
       "      <td>0.451399</td>\n",
       "      <td>0.178196</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>-0.066833</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>-0.005950</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(100).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8.719081</td>\n",
       "      <td>0.121731</td>\n",
       "      <td>0.265268</td>\n",
       "      <td>-0.193788</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.039432</td>\n",
       "      <td>-0.011615</td>\n",
       "      <td>-0.007887</td>\n",
       "      <td>0.020599</td>\n",
       "      <td>-0.012654</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(98).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-10.318301</td>\n",
       "      <td>0.773588</td>\n",
       "      <td>0.247358</td>\n",
       "      <td>0.162311</td>\n",
       "      <td>0.039235</td>\n",
       "      <td>0.048782</td>\n",
       "      <td>-0.041743</td>\n",
       "      <td>0.026801</td>\n",
       "      <td>0.020383</td>\n",
       "      <td>-0.009967</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(87).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.963363</td>\n",
       "      <td>-0.378007</td>\n",
       "      <td>0.150066</td>\n",
       "      <td>-0.258504</td>\n",
       "      <td>-0.005361</td>\n",
       "      <td>0.009539</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>-0.017333</td>\n",
       "      <td>0.011270</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(62).jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.145729</td>\n",
       "      <td>0.939426</td>\n",
       "      <td>0.297938</td>\n",
       "      <td>0.055525</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>-0.039451</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>-0.018045</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>fake</td>\n",
       "      <td>person(92).jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0 -11.605235  0.667623  0.451399  0.178196  0.035186  0.002500 -0.066833   \n",
       "1  -8.719081  0.121731  0.265268 -0.193788  0.015589  0.039432 -0.011615   \n",
       "2 -10.318301  0.773588  0.247358  0.162311  0.039235  0.048782 -0.041743   \n",
       "3  -4.963363 -0.378007  0.150066 -0.258504 -0.005361  0.009539  0.043594   \n",
       "4   6.145729  0.939426  0.297938  0.055525  0.046462 -0.039451  0.013124   \n",
       "\n",
       "          7         8         9 label            image  \n",
       "0  0.008642  0.003546 -0.005950  fake  person(100).jpg  \n",
       "1 -0.007887  0.020599 -0.012654  fake   person(98).jpg  \n",
       "2  0.026801  0.020383 -0.009967  fake   person(87).jpg  \n",
       "3  0.005366 -0.017333  0.011270  fake   person(62).jpg  \n",
       "4 -0.018045  0.000462  0.000765  fake   person(92).jpg  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle('df_pca_10').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcc29cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "embed_dataset = pd.read_pickle('embed_dataset.pkl')\n",
    "embedding_matrix = np.vstack(embed_dataset[\"embeddings\"].values)\n",
    "labels = embed_dataset[\"label\"].values\n",
    "image = embed_dataset[\"image\"].values\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(embedding_matrix)\n",
    "pca_df = pd.DataFrame(reduced_embeddings)\n",
    "pca_df[\"label\"] = labels\n",
    "pca_df[\"image\"] = image\n",
    " \n",
    "# Scree Plot\n",
    "import numpy as np\n",
    "# Bar plot of explained_variance\n",
    "plt.bar(\n",
    "    range(1,len(pca.explained_variance_)+1),\n",
    "    pca.explained_variance_\n",
    "    )\n",
    " \n",
    "plt.plot(\n",
    "    range(1,len(pca.explained_variance_ )+1),\n",
    "    np.cumsum(pca.explained_variance_),\n",
    "    c='red',\n",
    "    label='Cumulative Explained Variance')\n",
    " \n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Explained variance (eignenvalues)')\n",
    "plt.title('Scree plot')\n",
    " \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
